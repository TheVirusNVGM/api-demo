"""
AI Build Logic (Refactored)
3-Layer Architecture:
  Layer 0: Query Planner (AI) ‚Üí –°–æ–∑–¥–∞—ë—Ç –ø–ª–∞–Ω –ø–æ–∏—Å–∫–∞
  Layer 1: Hybrid Search ‚Üí –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
  Layer 2: Final Selector (AI) ‚Üí –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–±–æ—Ä –º–æ–¥–æ–≤
"""

from typing import List, Dict
from query_planner import create_search_plan
from hybrid_search import execute_search_plan
from final_selector import select_final_mods, enrich_mods_with_full_data
from pipeline_transparency import create_pipeline
from performance_optimizer import get_performance_optimizer
from architecture_matcher import (
    find_reference_modpacks,
    extract_capability_patterns,
    format_for_ai_context
)


def build_modpack(
    prompt: str,
    mc_version: str,
    mod_loader: str,
    current_mods: List[str],
    max_mods: int,
    fabric_compat_mode: bool,
    deepseek_key: str,
    supabase_url: str,
    supabase_key: str
) -> Dict:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –º–æ–¥–ø–∞–∫ –∏—Å–ø–æ–ª—å–∑—É—è 3-layer AI –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
    
    Args:
        prompt: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        mc_version: –í–µ—Ä—Å–∏—è Minecraft
        mod_loader: –ó–∞–≥—Ä—É–∑—á–∏–∫ (fabric/forge/neoforge)
        current_mods: –ú–æ–¥—ã —É–∂–µ –Ω–∞ –¥–æ—Å–∫–µ (project_ids)
        max_mods: –ú–∞–∫—Å–∏–º—É–º –º–æ–¥–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        deepseek_key: API –∫–ª—é—á DeepSeek
        supabase_url: URL Supabase
        supabase_key: –ö–ª—é—á Supabase
    
    Returns:
        Dict —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –º–æ–¥–∞–º–∏ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
    """
    
    print("="*80)
    print("üöÄ Starting AI Modpack Builder (3-Layer Architecture)")
    print("="*80)
    print(f"üìù User Prompt: {prompt}")
    print(f"üéÆ Version: {mc_version}, Loader: {mod_loader}")
    print(f"üì¶ Current mods: {len(current_mods)}, Max new mods: {max_mods}")
    print()
    
    # –°–æ–∑–¥–∞—ë–º pipeline execution –¥–ª—è –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏
    pipeline = create_pipeline(prompt, mc_version, mod_loader)
    print(f"üÜî Pipeline ID: {pipeline.pipeline_id}")
    print()
    
    # Fabric Compatibility Mode (–ø–µ—Ä–µ–¥–∞–Ω –∏–∑ –ª–∞—É–Ω—á–µ—Ä–∞)
    if fabric_compat_mode:
        print("üîß Fabric Compatibility Mode: ENABLED (user toggled)")
        print("   ‚Üí Accepting both Fabric and NeoForge/Forge mods")
    else:
        print("üîß Fabric Compatibility Mode: DISABLED")
        print(f"   ‚Üí Only accepting {mod_loader} mods")
    print()
    
    # ========================================================================
    # LAYER 0: QUERY PLANNER (AI)
    # ========================================================================
    print("[LAYER 0] Query Planner")
    print("-" * 80)
    
    search_plan = create_search_plan(
        user_prompt=prompt,
        mc_version=mc_version,
        mod_loader=mod_loader,
        current_mods=current_mods,
        max_mods=max_mods,
        deepseek_key=deepseek_key,
        fabric_compat_mode=fabric_compat_mode
    )
    pipeline.set_query_plan(search_plan)
    
    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã Query Planner
    if '_tokens' in search_plan:
        tokens_info = search_plan['_tokens']
        pipeline.track_ai_call(
            tokens_info['total_tokens'],
            tokens_info['cost_usd']
        )
    
    print()
    
    # ========================================================================
    # LAYER 1: HYBRID SEARCH ENGINE
    # ========================================================================
    print("[LAYER 1] Hybrid Search Engine")
    print("-" * 80)
    
    candidates = execute_search_plan(
        search_plan=search_plan,
        supabase_url=supabase_url,
        supabase_key=supabase_key,
        fabric_compat_mode=fabric_compat_mode  # –ü–µ—Ä–µ–¥–∞—ë–º –ø–∞—Ä–∞–º–µ—Ç—Ä!
    )
    
    # –û–±–æ–≥–∞—â–∞–µ–º candidates layer metadata –¥–ª—è performance-–∑–∞–ø—Ä–æ—Å–æ–≤
    if 'performance' in prompt.lower() or 'optimization' in prompt.lower() or 'fps' in prompt.lower():
        optimizer = get_performance_optimizer()
        candidates = optimizer.enrich_mods_with_layer_info(
            candidates, mod_loader, mc_version
        )
        print(f"   üè∑Ô∏è  Enriched {len([c for c in candidates if c.get('_optimization_layer')])} candidates with layer metadata")
    
    pipeline.set_candidates(candidates)
    print()
    
    if len(candidates) < 5:
        print(f"‚ö†Ô∏è  WARNING: Only {len(candidates)} candidates found!")
        print("   This might result in poor selection quality.")
        print()
    
    # ========================================================================
    # LAYER 1.5: ARCHITECTURE MATCHER (CONDITIONAL)
    # ========================================================================
    reference_context = None
    
    if search_plan.get('use_architecture_matcher', False):
        print("[LAYER 1.5] Architecture Matcher")
        print("-" * 80)
        
        try:
            # –ù–∞—Ö–æ–¥–∏–º reference –º–æ–¥–ø–∞–∫–∏
            reference_modpacks = find_reference_modpacks(
                user_prompt=prompt,
                mc_version=mc_version,
                mod_loader=mod_loader,
                supabase_url=supabase_url,
                supabase_key=supabase_key,
                top_n=5
            )
            
            if reference_modpacks:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                capability_patterns = extract_capability_patterns(reference_modpacks)
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è AI –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                reference_context = format_for_ai_context(
                    reference_modpacks,
                    capability_patterns,
                    max_context_length=3000
                )
                
                print(f"‚úÖ [Architecture Matcher] Generated reference context ({len(reference_context)} chars)")
            else:
                print("‚ö†Ô∏è  [Architecture Matcher] No reference modpacks found")
        
        except Exception as e:
            print(f"‚ùå [Architecture Matcher] Error: {e}")
            import traceback
            traceback.print_exc()
        
        print()
    else:
        request_type = search_plan.get('request_type', 'unknown')
        print(f"[SKIP] Architecture Matcher (request_type: {request_type})")
        print("-" * 80)
        print("   ‚Üí Not needed for this type of request")
        print()
    
    # ========================================================================
    # LAYER 2: FINAL SELECTOR (AI)
    # ========================================================================
    print("[LAYER 2] Final Selector")
    print("-" * 80)
    
    result = select_final_mods(
        candidates=candidates,
        user_prompt=prompt,
        current_mods=current_mods,
        max_mods=max_mods,
        deepseek_key=deepseek_key,
        reference_context=reference_context  # –ü–µ—Ä–µ–¥–∞—ë–º reference –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    )
    pipeline.set_selected_mods(result['mods'])
    
    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã Final Selector
    if '_tokens' in result:
        tokens_info = result['_tokens']
        pipeline.track_ai_call(
            tokens_info['total_tokens'],
            tokens_info['cost_usd']
        )
    
    print()
    
    # ========================================================================
    # PERFORMANCE OPTIMIZATION COVERAGE CHECK (–µ—Å–ª–∏ performance-–∑–∞–ø—Ä–æ—Å)
    # ========================================================================
    if 'performance' in prompt.lower() or 'optimization' in prompt.lower() or 'fps' in prompt.lower():
        print("[PERFORMANCE OPTIMIZATION] Coverage check...")
        print("-" * 80)
        
        optimizer = get_performance_optimizer()
        result['mods'], coverage_reasons = optimizer.ensure_minimum_coverage(
            selected_mods=result['mods'],
            candidates=candidates,
            mod_loader=mod_loader,
            mc_version=mc_version,
            max_additions=min(10, max_mods - len(result['mods']))
        )
        
        if coverage_reasons:
            pipeline.reasons_chosen.update({
                reason.split(' ')[1]: reason for reason in coverage_reasons
            })
        
        print()
    
    # ========================================================================
    # DATA ENRICHMENT (FETCH FULL MOD DATA INCLUDING DEPENDENCIES)
    # ========================================================================
    print("[DATA ENRICHMENT] Fetching full mod data...")
    print("-" * 80)
    
    result['mods'] = enrich_mods_with_full_data(
        selected_mods=result['mods'],
        supabase_url=supabase_url,
        supabase_key=supabase_key
    )
    print()
    
    # ========================================================================
    # FINAL RESULT
    # ========================================================================
    print("="*80)
    print("‚úÖ AI Modpack Builder Complete")
    print("="*80)
    print(f"üì¶ Selected: {len(result['mods'])} mods")
    if result['explanation']:
        print(f"üí° Explanation: {result['explanation'][:100]}...")
    print()
    print(pipeline.get_summary())
    print()
    
    # –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º pipeline –∏ –ø–æ–ª—É—á–∞–µ–º transparency report
    transparency_report = pipeline.finalize()
    
    return {
        'mods': result['mods'],
        'explanation': result['explanation'],
        'prompt': prompt,
        'mc_version': mc_version,
        'mod_loader': mod_loader,
        '_architecture': '3-layer',
        '_search_plan': search_plan.get('strategy'),
        '_candidates_count': len(candidates),
        '_pipeline': transparency_report
    }
