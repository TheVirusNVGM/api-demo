"""
AI Build Logic
–°–æ–±–∏—Ä–∞–µ—Ç –º–æ–¥–ø–∞–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
"""

import requests
import json
import re
from typing import List, Dict
from sentence_transformers import SentenceTransformer

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (–∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑)
embedding_model = None


def get_embedding_model():
    """–õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ embeddings"""
    global embedding_model
    if embedding_model is None:
        print("üì• Loading sentence-transformers model...")
        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        print("‚úÖ Model loaded")
    return embedding_model


def build_modpack(
    prompt: str,
    mc_version: str,
    mod_loader: str,
    current_mods: List[str],  # –°–ø–∏—Å–æ–∫ project_id –º–æ–¥–æ–≤ –Ω–∞ –¥–æ—Å–∫–µ
    max_mods: int,
    fabric_compat_mode: bool = False,  # –î–æ–±–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    deepseek_key: str = None,
    supabase_url: str = None,
    supabase_key: str = None
) -> Dict:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –º–æ–¥–ø–∞–∫ –∏—Å–ø–æ–ª—å–∑—É—è AI
    
    Args:
        prompt: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ("—Å–æ–±–µ—Ä–∏ –º–æ–¥–ø–∞–∫ –¥–ª—è PvP")
        mc_version: –í–µ—Ä—Å–∏—è Minecraft
        mod_loader: –ó–∞–≥—Ä—É–∑—á–∏–∫ (fabric/forge/neoforge)
        current_mods: –ú–æ–¥—ã —É–∂–µ –Ω–∞ –¥–æ—Å–∫–µ
        max_mods: –ú–∞–∫—Å–∏–º—É–º –º–æ–¥–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        deepseek_key: API –∫–ª—é—á DeepSeek
        supabase_url: URL Supabase
        supabase_key: –ö–ª—é—á Supabase
    
    Returns:
        Dict —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –º–æ–¥–∞–º–∏ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
    """
    
    # 1. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embedding –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
    print("üß† Generating query embedding...")
    model = get_embedding_model()
    query_embedding = model.encode(prompt).tolist()
    
    # 2. –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ Supabase
    print("üîç Searching for candidate mods...")
    
    response = requests.post(
        f'{supabase_url}/rest/v1/rpc/search_mods_semantic',
        headers={
            'apikey': supabase_key,
            'Authorization': f'Bearer {supabase_key}',
            'Content-Type': 'application/json'
        },
        json={
            'query_embedding': query_embedding,
            'match_count': 300  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è
        }
    )
    
    if response.status_code != 200:
        raise Exception(f"Supabase error: {response.status_code} - {response.text}")
    
    candidates = response.json()
    print(f"‚úÖ Found {len(candidates)} candidate mods")
    
    # –î–µ–±–∞–≥: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    if candidates:
        print("üîç Top 10 semantic search results:")
        for i, mod in enumerate(candidates[:10], 1):
            print(f"   {i}. {mod.get('name')} ({mod.get('slug')}) - {mod.get('loaders', [])}")
    
    # 3. –£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å —É—á—ë—Ç–æ–º Fabric Compat Mode
    # Fabric Compat Mode –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–∫–ª—é—á—ë–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
    has_fabric_compat = fabric_compat_mode
    
    if has_fabric_compat:
        print("üîß Fabric Compat Mode: ENABLED (user toggled)")
        print("   Accepting both fabric AND neoforge/forge mods")
    
    filtered_candidates = []
    for mod in candidates:
        mod_versions = mod.get('mc_versions', [])
        mod_loaders = mod.get('loaders', [])
        
        version_ok = mc_version in mod_versions if mod_versions else True
        
        # –õ–æ–≥–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ loader
        if has_fabric_compat:
            # FabricFix –∞–∫—Ç–∏–≤–µ–Ω - –ø—Ä–∏–Ω–∏–º–∞–µ–º –∏ fabric –∏ neoforge/forge
            loader_ok = any(loader in mod_loaders for loader in ['fabric', 'neoforge', 'forge']) if mod_loaders else True
            
            # –ü–æ–º–µ—á–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è NeoForge –≤–µ—Ä—Å–∏–π
            if version_ok and loader_ok:
                mod['_prefers_neoforge'] = 'neoforge' in mod_loaders or 'forge' in mod_loaders
        else:
            # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º - —Ç–æ–ª—å–∫–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π loader
            loader_ok = mod_loader in mod_loaders if mod_loaders else True
        
        if version_ok and loader_ok:
            filtered_candidates.append(mod)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ NeoForge –º–æ–¥—ã, –ø–æ—Ç–æ–º Fabric
    if has_fabric_compat:
        filtered_candidates.sort(key=lambda m: (not m.get('_prefers_neoforge', False), -m.get('downloads', 0)))
    
    print(f"‚úÖ After filtering: {len(filtered_candidates)} compatible mods")
    
    # –õ–æ–≥–∏—Ä—É–µ–º, –µ—Å–ª–∏ –º–∞–ª–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    if len(filtered_candidates) < 20:
        print(f"‚ö†Ô∏è  WARNING: Only {len(filtered_candidates)} compatible mods found!")
        print(f"   Filters: mc_version={mc_version}, mod_loader={mod_loader}, has_fabric_compat={has_fabric_compat}")
        if candidates:
            sample = candidates[0]
            print(f"   Sample mod versions: {sample.get('mc_versions', [])}")
            print(f"   Sample mod loaders: {sample.get('loaders', [])}")
    
    # 4. –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è DeepSeek
    current_mods_text = ""
    if current_mods:
        current_mods_text = f"CURRENT MODS ON BOARD ({len(current_mods)} mods):\n"
        # current_mods - —ç—Ç–æ —Å–ø–∏—Å–æ–∫ project_id
        for mod_id in current_mods[:50]:  # –ú–∞–∫—Å–∏–º—É–º 50 –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            current_mods_text += f"- {mod_id}\n"
        current_mods_text += "\n"
    
    candidates_text = "CANDIDATE MODS (choose from these):\n"
    for i, mod in enumerate(filtered_candidates[:100], 1):
        candidates_text += f"{i}. [{mod['slug']}] {mod['name']}\n"
        candidates_text += f"   {mod.get('description', '')[:150]}\n"
        candidates_text += f"   Categories: {', '.join(mod.get('categories', []))}\n"
        candidates_text += f"   Downloads: {mod.get('downloads', 0):,}\n\n"
    
    prompt_text = f"""You are an expert Minecraft modpack builder. Your task is to PRECISELY follow user's request.

{current_mods_text}

USER REQUEST: "{prompt}"
Version: {mc_version}, Loader: {mod_loader}
Max mods to add: {max_mods}

{candidates_text}

CRITICAL RULES:
1. If user asks for SPECIFIC mods by name (e.g., "add sodium and iris", "–¥–æ–±–∞–≤—å —Å–æ–¥–∏—É–º –∏ –∏—Ä–∏—Å"):
   - Find EXACT matches in candidates list by name
   - ONLY select those specific mods
   - DO NOT add any extra mods
   - Common mod names: Sodium=sodium, Iris=iris, JEI=jei, Jade=jade, REI=rei

2. If user asks for a NUMBER of mods (e.g., "add 2 mods", "add 5 performance mods"):
   - Select EXACTLY that number
   - DO NOT exceed the requested count

3. If user asks for a CATEGORY (e.g., "optimization mods", "building mods"):
   - Select up to {max_mods} mods from that category
   - Focus on the most popular and stable

4. General guidelines:
   - Check current mods to avoid duplicates
   - Don't add dependencies unless explicitly needed
   - Prefer exact name matches over similar mods

RETURN ONLY VALID JSON:
{{
  "mods": [
    {{
      "slug": "mod-slug-from-candidates",
      "reason": "Brief reason (e.g., 'Requested by user', 'Popular optimization mod')"
    }}
  ],
  "explanation": "Short summary of what was added and why"
}}

EXAMPLES:
- Request: "add sodium" ‚Üí Select ONLY sodium mod
- Request: "add 3 optimization mods" ‚Üí Select EXACTLY 3 optimization mods
- Request: "building mods" ‚Üí Select various building-related mods (up to max_mods)
"""

    print("üì§ Sending to DeepSeek for final selection...")
    
    # 5. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ DeepSeek
    response = requests.post(
        'https://api.deepseek.com/v1/chat/completions',
        headers={
            'Authorization': f'Bearer {deepseek_key}',
            'Content-Type': 'application/json'
        },
        json={
            'model': 'deepseek-chat',
            'messages': [{
                'role': 'user',
                'content': prompt_text
            }],
            'temperature': 0.2,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            'max_tokens': 4000
        },
        timeout=60
    )
    
    if response.status_code != 200:
        raise Exception(f"DeepSeek API error: {response.status_code} - {response.text}")
    
    result = response.json()
    content = result['choices'][0]['message']['content']
    
    print("üì• Received response from DeepSeek")
    
    # 6. –ü–∞—Ä—Å–∏–º JSON
    json_match = re.search(r'\{.*\}', content, re.DOTALL)
    if not json_match:
        raise Exception("Could not parse JSON from AI response")
    
    selection = json.loads(json_match.group())
    
    # 7. –û–±–æ–≥–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    selected_mods = []
    candidates_dict = {m['slug']: m for m in filtered_candidates}
    
    for mod_selection in selection['mods']:
        slug = mod_selection['slug']
        if slug in candidates_dict:
            mod_data = candidates_dict[slug].copy()
            mod_data['ai_reason'] = mod_selection['reason']
            selected_mods.append(mod_data)
    
    print(f"‚úÖ Selected {len(selected_mods)} mods")
    
    return {
        'mods': selected_mods,
        'explanation': selection.get('explanation', ''),
        'prompt': prompt,
        'mc_version': mc_version,
        'mod_loader': mod_loader
    }