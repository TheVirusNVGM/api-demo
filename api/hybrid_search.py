"""
Layer 1: Hybrid Search Engine
–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–ª–∞–Ω –ø–æ–∏—Å–∫–∞, –∫–æ–º–±–∏–Ω–∏—Ä—É—è –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏ keyword –ø–æ–∏—Å–∫ —Å BM25
"""

import requests
from typing import Dict, List, Tuple
from sentence_transformers import SentenceTransformer
from collections import defaultdict
import math
import re
from config import BM25_K1, BM25_B, CONNECTOR_MODS, CATEGORY_SYNONYMS

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å embeddings
embedding_model = None


def get_embedding_model():
    """–õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ embeddings"""
    global embedding_model
    if embedding_model is None:
        print("üì• [Hybrid Search] Loading sentence-transformers model...")
        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        print("‚úÖ [Hybrid Search] Model loaded")
    return embedding_model


def execute_search_plan(
    search_plan: Dict,
    supabase_url: str,
    supabase_key: str
) -> List[Dict]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–ª–∞–Ω –ø–æ–∏—Å–∫–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç candidates
    
    Args:
        search_plan: –ü–ª–∞–Ω –ø–æ–∏—Å–∫–∞ –æ—Ç Query Planner
        supabase_url: URL Supabase
        supabase_key: –ö–ª—é—á Supabase
    
    Returns:
        List –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å scores
    """
    
    print(f"üîç [Hybrid Search] Executing search plan...")
    
    # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata = search_plan.get('_metadata', {})
    mc_version = metadata.get('mc_version', '1.21.1')
    mod_loader = metadata.get('mod_loader', 'fabric')
    fabric_compat_mode = metadata.get('fabric_compat_mode', False)
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç –≤—Å–µ—Ö queries
    all_results = []
    
    for query_config in search_plan.get('search_queries', []):
        query_type = query_config.get('type', 'semantic')
        query_text = query_config.get('text', '')
        weight = query_config.get('weight', 1.0)
        limit = query_config.get('limit', 100)
        
        print(f"   üîé {query_type.upper()} query: \"{query_text[:50]}...\" (weight={weight})")
        
        if query_type == 'semantic':
            results = vector_search(
                query_text=query_text,
                limit=limit,
                supabase_url=supabase_url,
                supabase_key=supabase_key
            )
        elif query_type == 'keyword':
            results = keyword_search(
                query_text=query_text,
                limit=limit,
                supabase_url=supabase_url,
                supabase_key=supabase_key
            )
        else:
            print(f"   ‚ö†Ô∏è  Unknown query type: {query_type}")
            continue
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–µ—Å –∫ scores
        for mod in results:
            mod['_search_score'] = mod.get('_search_score', 1.0) * weight
            mod['_search_type'] = query_type
        
        all_results.extend(results)
        print(f"      ‚Üí Found {len(results)} mods")
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (Reciprocal Rank Fusion - —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
    print(f"üîó [Hybrid Search] Fusing {len(all_results)} results...")
    fused_results = fuse_results(all_results)
    
    print(f"   ‚Üí {len(fused_results)} unique mods after fusion")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
    print(f"üîß [Hybrid Search] Applying filters...")
    filtered_results = apply_filters(
        candidates=fused_results,
        filters=search_plan.get('filters', {}),
        mc_version=mc_version,
        mod_loader=mod_loader,
        fabric_compat_mode=fabric_compat_mode
    )
    
    print(f"   ‚Üí {len(filtered_results)} mods after filtering")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º diversity rules (–Ω–æ –Ω–µ –¥–ª—è optimization/performance)
    filters = search_plan.get('filters', {})
    categories_include = filters.get('categories_include', [])
    
    # –î–ª—è optimization/performance –∑–∞–ø—Ä–æ—Å–æ–≤ diversity –Ω–µ –Ω—É–∂–µ–Ω
    skip_diversity = any(cat in ['optimization', 'performance'] for cat in categories_include)
    
    if skip_diversity:
        print(f"üé® [Hybrid Search] Skipping diversity check for optimization query...")
        diverse_results = filtered_results
        print(f"   ‚Üí Keeping all {len(diverse_results)} optimization mods")
    else:
        print(f"üé® [Hybrid Search] Ensuring diversity...")
        diverse_results = ensure_diversity(
            candidates=filtered_results,
            diversity_rules=search_plan.get('diversity', {})
        )
        print(f"   ‚Üí {len(diverse_results)} mods after diversity check")
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–æ target_count
    target_count = search_plan.get('target_count', 100)
    final_results = diverse_results[:target_count]
    
    print(f"‚úÖ [Hybrid Search] Returning {len(final_results)} candidates")
    
    return final_results


def vector_search(
    query_text: str,
    limit: int,
    supabase_url: str,
    supabase_key: str
) -> List[Dict]:
    """
    –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Supabase
    """
    model = get_embedding_model()
    query_embedding = model.encode(query_text).tolist()
    
    response = requests.post(
        f'{supabase_url}/rest/v1/rpc/search_mods_semantic',
        headers={
            'apikey': supabase_key,
            'Authorization': f'Bearer {supabase_key}',
            'Content-Type': 'application/json'
        },
        json={
            'query_embedding': query_embedding,
            'match_count': limit
        },
        timeout=30
    )
    
    if response.status_code != 200:
        print(f"   ‚ö†Ô∏è  Vector search failed: {response.status_code}")
        print(f"   Error: {response.text}")
        return []
    
    results = response.json()
    
    # –î–æ–±–∞–≤–ª—è–µ–º search score (distance ‚Üí similarity)
    for mod in results:
        # Supabase –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç distance (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ similarity (–±–æ–ª—å—à–µ = –ª—É—á—à–µ)
        distance = mod.get('distance', 1.0)
        mod['_search_score'] = 1.0 / (1.0 + distance)
    
    return results


def keyword_search(
    query_text: str,
    limit: int,
    supabase_url: str,
    supabase_key: str
) -> List[Dict]:
    """
    Keyword –ø–æ–∏—Å–∫ —Å BM25 scoring
    BM25 - —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è IR
    """
    keywords = [w.lower() for w in query_text.split() if len(w) > 2]
    
    if not keywords:
        return []
    
    # –§–µ—Ç—á–∏–º –º–æ–¥—ã –¥–ª—è BM25 scoring
    # –°—Ç—Ä–æ–∏–º OR –∑–∞–ø—Ä–æ—Å –¥–ª—è –í–°–ï–• keywords (–Ω–µ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–≥–æ!)
    or_conditions = []
    for keyword in keywords:
        or_conditions.append(f'name.ilike.*{keyword}*')
        or_conditions.append(f'summary.ilike.*{keyword}*')
        or_conditions.append(f'description.ilike.*{keyword}*')
    
    or_query = ','.join(or_conditions)
    
    response = requests.get(
        f'{supabase_url}/rest/v1/mods',
        headers={
            'apikey': supabase_key,
            'Authorization': f'Bearer {supabase_key}',
        },
        params={
            'or': f'({or_query})',
            'limit': limit * 3  # –ë–µ—Ä—ë–º –±–æ–ª—å—à–µ –¥–ª—è –ª—É—á—à–µ–≥–æ BM25
        },
        timeout=30
    )
    
    if response.status_code != 200:
        print(f"   ‚ö†Ô∏è  Keyword search failed: {response.status_code}")
        return []
    
    results = response.json()
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º BM25 scoring
    results_with_bm25 = calculate_bm25_scores(results, keywords)
    
    # EXACT MATCH BOOST
    for mod in results_with_bm25:
        mod_slug = mod.get('slug', '').lower()
        mod_name = mod.get('name', '').lower()
        
        for keyword in keywords:
            keyword_lower = keyword.lower()
            if mod_slug == keyword_lower or mod_name == keyword_lower:
                mod['_search_score'] = mod.get('_search_score', 0) * 10
                mod['_exact_match'] = True
                break
    
    results_with_bm25.sort(key=lambda m: m.get('_search_score', 0), reverse=True)
    return results_with_bm25[:limit]


def calculate_bm25_scores(documents: List[Dict], query_terms: List[str], k1: float = BM25_K1, b: float = BM25_B) -> List[Dict]:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç BM25 scores –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    
    BM25 Formula:
    score(D,Q) = Œ£ IDF(qi) * (f(qi,D) * (k1 + 1)) / (f(qi,D) + k1 * (1 - b + b * |D| / avgdl))
    
    Args:
        documents: –°–ø–∏—Å–æ–∫ –º–æ–¥–æ–≤
        query_terms: –¢–µ—Ä–º–∏–Ω—ã –∑–∞–ø—Ä–æ—Å–∞
        k1: –ü–∞—Ä–∞–º–µ—Ç—Ä –Ω–∞—Å—ã—â–µ–Ω–∏—è (–æ–±—ã—á–Ω–æ 1.2-2.0)
        b: –ü–∞—Ä–∞–º–µ—Ç—Ä –¥–ª–∏–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–æ–±—ã—á–Ω–æ 0.75)
    
    Returns:
        –î–æ–∫—É–º–µ–Ω—Ç—ã —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º _search_score
    """
    if not documents or not query_terms:
        return documents
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    doc_texts = []
    for mod in documents:
        # –í–µ—Å–∞: –∏–º—è (3x) + summary (2x) + tags (2x) + description (1x)
        name = mod.get('name', '')
        summary = mod.get('summary', '')
        tags = ' '.join(mod.get('tags', []))
        desc = mod.get('description', '')[:500]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º description
        
        # –ü–æ–≤—Ç–æ—Ä—è–µ–º –≤–∞–∂–Ω—ã–µ —á–∞—Å—Ç–∏ –¥–ª—è –≤–µ—Å–∞
        text = f"{name} {name} {name} {summary} {summary} {tags} {tags} {desc}"
        doc_texts.append(text.lower())
    
    # –í—ã—á–∏—Å–ª—è–µ–º avgdl (—Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞)
    doc_lengths = [len(text.split()) for text in doc_texts]
    avgdl = sum(doc_lengths) / len(doc_lengths) if doc_lengths else 1
    
    N = len(documents)  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    
    # –í—ã—á–∏—Å–ª—è–µ–º IDF –¥–ª—è –∫–∞–∂–¥–æ–≥–æ query term
    idf_scores = {}
    for term in query_terms:
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö term
        df = sum(1 for text in doc_texts if term in text)
        # IDF = log((N - df + 0.5) / (df + 0.5) + 1)
        idf = math.log((N - df + 0.5) / (df + 0.5) + 1) if df > 0 else 0
        idf_scores[term] = idf
    
    # –í—ã—á–∏—Å–ª—è–µ–º BM25 score –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    for i, mod in enumerate(documents):
        text = doc_texts[i]
        doc_len = doc_lengths[i]
        
        score = 0.0
        for term in query_terms:
            if term not in text:
                continue
            
            # –ß–∞—Å—Ç–æ—Ç–∞ —Ç–µ—Ä–º–∏–Ω–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
            tf = text.count(term)
            
            # IDF —Ç–µ—Ä–º–∏–Ω–∞
            idf = idf_scores.get(term, 0)
            
            # BM25 component
            numerator = tf * (k1 + 1)
            denominator = tf + k1 * (1 - b + b * (doc_len / avgdl))
            
            score += idf * (numerator / denominator)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º score (–¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞, —á—Ç–æ–±—ã –±—ã–ª –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 0-1)
        mod['_search_score'] = min(score / (len(query_terms) * 5), 1.0)
        mod['_bm25_raw'] = score
    
    return documents


def fuse_results(results: List[Dict]) -> List[Dict]:
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç —Ä–∞–∑–Ω—ã—Ö queries
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Reciprocal Rank Fusion (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
    """
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ slug
    mods_dict = {}
    
    for mod in results:
        slug = mod.get('slug')
        if not slug:
            continue
        
        if slug not in mods_dict:
            mods_dict[slug] = mod.copy()
            mods_dict[slug]['_combined_score'] = 0
            mods_dict[slug]['_search_types'] = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º score
        score = mod.get('_search_score', 0)
        mods_dict[slug]['_combined_score'] += score
        
        # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –æ—Ç–∫—É–¥–∞ –ø—Ä–∏—à—ë–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        search_type = mod.get('_search_type', 'unknown')
        if search_type not in mods_dict[slug]['_search_types']:
            mods_dict[slug]['_search_types'].append(search_type)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ combined score
    fused = sorted(
        mods_dict.values(),
        key=lambda m: m['_combined_score'],
        reverse=True
    )
    
    return fused


def apply_filters(
    candidates: List[Dict],
    filters: Dict,
    mc_version: str,
    mod_loader: str,
    fabric_compat_mode: bool
) -> List[Dict]:
    """
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º
    """
    filtered = []
    
    exclude_ids = set(filters.get('exclude_project_ids', []))
    min_downloads = filters.get('min_downloads', 0)
    categories_include = set(filters.get('categories_include', []))
    categories_prefer = set(filters.get('categories_prefer', []))
    required_capabilities = set(filters.get('required_capabilities', []))
    preferred_capabilities = set(filters.get('preferred_capabilities', []))
    
    # DEBUG: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
    if required_capabilities or preferred_capabilities:
        print(f"   üîß Filters: min_downloads={min_downloads}, required_capabilities={required_capabilities}")
    else:
        print(f"   üîß Filters: min_downloads={min_downloads}, categories_include={categories_include}")
    
    
    for mod in candidates:
        # –ò—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ
        if mod.get('source_id') in exclude_ids or mod.get('slug') in exclude_ids:
            print(f"   ‚è≠Ô∏è  Skipped (already added): {mod.get('slug')}")
            continue
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –º–æ–¥—ã (reported_count >= 3)
        incompatibilities = mod.get('incompatibilities', {})
        if isinstance(incompatibilities, dict) and '_OUTDATED_' in incompatibilities:
            reported_count = incompatibilities['_OUTDATED_'].get('reported_count', 0)
            if reported_count >= 3:
                print(f"   ‚è≠Ô∏è  Skipped (outdated): {mod.get('slug')} - reported {reported_count} times")
                continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –º–æ–¥–∞–º–∏ —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ
        if isinstance(incompatibilities, dict):
            is_incompatible = False
            for other_mod in filtered:
                other_id = other_mod.get('source_id') or other_mod.get('slug')
                if other_id in incompatibilities:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º loader-specific –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    incompat_info = incompatibilities[other_id]
                    if isinstance(incompat_info, dict):
                        incompat_loaders = incompat_info.get('loaders')
                        # –ï—Å–ª–∏ loaders –Ω–µ —É–∫–∞–∑–∞–Ω—ã - –≥–ª–æ–±–∞–ª—å–Ω–∞—è –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
                        if not incompat_loaders or mod_loader in incompat_loaders:
                            print(f"   ‚è≠Ô∏è  Skipped (incompatible): {mod.get('slug')} ‚ÜîÔ∏è {other_mod.get('slug')}")
                            is_incompatible = True
                            break
            
            if is_incompatible:
                continue
        
        # –ú–∏–Ω–∏–º—É–º –∑–∞–≥—Ä—É–∑–æ–∫
        if mod.get('downloads', 0) < min_downloads:
            print(f"   ‚è≠Ô∏è  Skipped (low downloads): {mod.get('slug')} - {mod.get('downloads', 0)} < {min_downloads}")
            continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ MC
        mod_versions = mod.get('mc_versions', [])
        if mod_versions and mc_version not in mod_versions:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º partial match (–Ω–∞–ø—Ä–∏–º–µ—Ä "1.21.1" –≤ ["1.21"])
            version_match = any(
                mc_version.startswith(v) or v.startswith(mc_version)
                for v in mod_versions
            )
            if not version_match:
                continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ loader
        mod_loaders = mod.get('loaders', [])
        if mod_loaders:
            if fabric_compat_mode:
                # –ü—Ä–∏–Ω–∏–º–∞–µ–º –∏ fabric –∏ neoforge/forge
                loader_ok = any(loader in mod_loaders for loader in ['fabric', 'neoforge', 'forge'])
                if loader_ok:
                    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç NeoForge
                    mod['_prefers_neoforge'] = 'neoforge' in mod_loaders or 'forge' in mod_loaders
            else:
                loader_ok = mod_loader in mod_loaders
            
            if not loader_ok:
                continue
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã) - –∏—Å–ø–æ–ª—å–∑—É–µ–º modrinth_categories + tags
        mod_categories = set(mod.get('modrinth_categories', []))
        mod_tags = set(mod.get('tags', []))
        all_categories = mod_categories | mod_tags
        
        if categories_include:
            
            has_matching_category = False
            for required_cat in categories_include:
                # –ü–æ–ª—É—á–∞–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è required –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                synonyms = CATEGORY_SYNONYMS.get(required_cat.lower(), {required_cat.lower()})
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
                for mod_cat in all_categories:
                    mod_cat_lower = mod_cat.lower()
                    for synonym in synonyms:
                        if synonym in mod_cat_lower or mod_cat_lower in synonym:
                            has_matching_category = True
                            break
                    if has_matching_category:
                        break
                if has_matching_category:
                    break
            
            if not has_matching_category:
                # –ù–µ –ª–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π skip - —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å–ø–∞–º–∞
                continue
        
        # –ë–æ–Ω—É—Å –∑–∞ –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if categories_prefer and all_categories.intersection(categories_prefer):
            mod['_combined_score'] = mod.get('_combined_score', 0) * 1.2
        
        # Capability-based scoring (–Ω–µ —Ñ–∏–ª—å—Ç—Ä!)
        mod_capabilities = set(mod.get('capabilities', []))
        
        # –ë–æ–Ω—É—Å –∑–∞ required capabilities (—Å–∏–ª—å–Ω—ã–π)
        if required_capabilities and mod_capabilities.intersection(required_capabilities):
            mod['_combined_score'] = mod.get('_combined_score', 0) * 1.5
        
        # –ë–æ–Ω—É—Å –∑–∞ preferred capabilities (—Å—Ä–µ–¥–Ω–∏–π)
        if preferred_capabilities and mod_capabilities.intersection(preferred_capabilities):
            mod['_combined_score'] = mod.get('_combined_score', 0) * 1.2
        
        filtered.append(mod)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º: NeoForge –º–æ–¥—ã —Å–Ω–∞—á–∞–ª–∞ (–µ—Å–ª–∏ fabric compat)
    if fabric_compat_mode:
        filtered.sort(
            key=lambda m: (
                not m.get('_prefers_neoforge', False),
                -m.get('_combined_score', 0),
                -m.get('downloads', 0)
            )
        )
    else:
        filtered.sort(
            key=lambda m: (-m.get('_combined_score', 0), -m.get('downloads', 0))
        )
    
    return filtered


def ensure_diversity(
    candidates: List[Dict],
    diversity_rules: Dict
) -> List[Dict]:
    """
    –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ù–ê–®–ò —Ç–µ–≥–∏ (393 —à—Ç) —Å fallback –Ω–∞ modrinth_categories
    """
    if not diversity_rules.get('ensure_variety', False):
        return candidates
    
    # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π –ª–∏–º–∏—Ç - 50 –º–æ–¥–æ–≤ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    max_per_category = diversity_rules.get('max_per_category', 50)
    
    # –°—á–∏—Ç–∞–µ–º –º–æ–¥—ã per category
    category_counts = defaultdict(int)
    diverse_results = []
    
    for mod in candidates:
        # –ü–†–ò–û–†–ò–¢–ï–¢: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ù–ê–®–ò —Ç–µ–≥–∏ (393 —à—Ç)
        our_tags = mod.get('tags', [])
        
        if our_tags and isinstance(our_tags, list) and len(our_tags) > 0:
            # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π —Ç–µ–≥ –∫–∞–∫ primary category
            # –ù–∞—à–∏ —Ç–µ–≥–∏ –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ!
            primary_category = our_tags[0] if isinstance(our_tags[0], str) else 'other'
        else:
            # FALLBACK: –ï—Å–ª–∏ –Ω–µ—Ç —Ç–µ–≥–æ–≤ - —Å–º–æ—Ç—Ä–∏–º modrinth_categories
            modrinth_cats = mod.get('modrinth_categories', [])
            primary_category = modrinth_cats[0] if modrinth_cats else 'other'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç
        if category_counts[primary_category] < max_per_category:
            diverse_results.append(mod)
            category_counts[primary_category] += 1
    
    return diverse_results
